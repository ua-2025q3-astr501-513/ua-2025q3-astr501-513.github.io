{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Root Finding and Optimization Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "In computational physics and astrophysics, many problems reduce to two\n",
    "fundamental kinds:\n",
    "1. Root finding:\n",
    "   Where does a function vanish?\n",
    "   I.e., solve $f(x) = 0$.\n",
    "2. Optimization:\n",
    "   Where does a function reach an extremum (minimum or maximum)?\n",
    "   I.e., solve $\\nabla f(x) = 0$.\n",
    "\n",
    "These two kind of problems are deeply connected.\n",
    "Optimization often boils down to root finding on the derivative.\n",
    "And root finding sometimes requires optimization-like strategies\n",
    "to accelerate convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Some classic examples of root finding include:\n",
    "* Solving Kepler's equation $M = E - e \\sin E$ to predict planetary\n",
    "  orbits.\n",
    "* Finding eigenfrequencies of stellar oscillations by locating roots\n",
    "  of characteristic equations.\n",
    "\n",
    "as well as optimization:\n",
    "* Determining the launch angle of a projectile for maximum range.\n",
    "* Fitting astrophysical models to observational data by minimizing a\n",
    "  chi-square error function.\n",
    "* Training machine learning models for data analysis in astronomy.\n",
    "\n",
    "In simple cases, closed-form solutions exist (e.g. projectile motion\n",
    "without air drag).\n",
    "However, in realistic systems, equations are often nonlinear,\n",
    "high-dimensional, and analytically unsolvable.\n",
    "Numerical root finding and optimization methods are the only way to\n",
    "solve these systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## General Framework of Interating Algorithms\n",
    "\n",
    "Root finding means solving\n",
    "\\begin{align}\n",
    "  f(x) = 0.\n",
    "\\end{align}\n",
    "Many algorithms approach this through **iteration**:\n",
    "starting from an initial guess, we repeatedly update $x$ until the\n",
    "error is small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Fixed-Point Viewpoint\n",
    "\n",
    "A powerful way to unify root-finding methods is to rewrite the problem\n",
    "as a fixed-point equation:\n",
    "\\begin{align}\n",
    "  x = g(x).\n",
    "\\end{align}\n",
    "\n",
    "Then we can iterate:\n",
    "\\begin{align}\n",
    "  x_{n+1} = g(x_n).\n",
    "\\end{align}\n",
    "\n",
    "The solution $x^*$ is a *fixed point* of $g(x)$.\n",
    "If the update rule is well chosen, the iteration converges to $x^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Convergence Criterion\n",
    "\n",
    "Near the fixed point $x^*$, expand $g(x)$ in a Taylor series:\n",
    "\\begin{align}\n",
    "  x_{n+1} = g(x_n) &\\approx g(x^*) + g'(x^*) (x_n - x^*) = x^* + g'(x^*) (x_n - x^*).\n",
    "\\end{align}\n",
    "Therefore,  \n",
    "\\begin{align}\n",
    "  \\frac{x_{n-1} - x^*}{x_n - x^*} &\\approx g'(x^*).\n",
    "\\end{align}\n",
    "\n",
    "It is clear that,\n",
    "* If $|g'(x^*)| < 1$, the error shrinks, and the iteration converges.\n",
    "* If $|g'(x^*)| > 1$, the iteration diverges.\n",
    "* The closer $|g'(x^*)|$ is to 0, the faster the convergence.\n",
    "\n",
    "This provides a general way to compare methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Classical Root Finders\n",
    "\n",
    "As we will soon see, classical root finding methods can be fitted into\n",
    "this picture.\n",
    "* Bisection Method:\n",
    "  Is repeatedly shrinking an interval where the root must lie.\n",
    "  The update rule is kind of a \"double fixed-point scheme\" where both\n",
    "  the upper and lower bounds converge to the root.\n",
    "  It is guaranteed to converge but only linearly.\n",
    "* Newton–Raphson Method:\n",
    "  Corresponds to choosing\n",
    "  \\begin{align}\n",
    "    g(x) = x - \\frac{f(x)}{f'(x)}.\n",
    "  \\end{align}\n",
    "  If $f'(x^*) \\neq 0$, this converges quadratically near the root.\n",
    "* Secant Method:\n",
    "  Uses the same Newton update rule, but replaces $f'(x)$ with a finite\n",
    "  difference.\n",
    "  This still fits into the fixed-point framework, with a convergence\n",
    "  rate between bisection and Newton.\n",
    "\n",
    "Thus, all root-finding methods can be viewed as different choices of\n",
    "$g(x)$, with a trade-off between robustness and speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Let's solve $f(x)=x^2-2=0$.  \n",
    "One possible choice of $g(x)$ is\n",
    "\\begin{align}\n",
    "  g(x) = \\tfrac12\\left(x + \\tfrac{2}{x}\\right).\n",
    "\\end{align}\n",
    "This is the\n",
    "[ancient Babylonian update](https://www.sciencedirect.com/science/article/pii/S0315086022000477)\n",
    "for $\\sqrt{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    return (x + 2/x)/2\n",
    "\n",
    "x = 1.0\n",
    "for i in range(5):\n",
    "    print(f\"Iteration {i}: x = {x}\")\n",
    "    x = g(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "which converges very quickly to $\\sqrt{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Bisection Method\n",
    "\n",
    "The Bisection Method is the simplest root-finding algorithm.\n",
    "It trades speed for guaranteed convergence.\n",
    "This makes it the \"workhorse\" method when robustness is more important\n",
    "than efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Suppose $f(x)$ is continuous on an interval $[a,b]$.\n",
    "If $f(a)$ and $f(b)$ have opposite signs, then by the\n",
    "[Intermediate Value Theorem](https://en.wikipedia.org/wiki/Intermediate_value_theorem),\n",
    "there exists at least one root in $(a,b)$.\n",
    "\n",
    "The bisection method works by repeatedly halving the interval:\n",
    "1. Compute the midpoint $m = (a+b)/2$.\n",
    "2. Evaluate $f(m)$.\n",
    "3. Select the half-interval $[a,m]$ or $[m,b]$ that contains the sign\n",
    "   change.\n",
    "4. Repeat until the interval is smaller than a desired tolerance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Convergence\n",
    "\n",
    "Each step reduces the interval length by half:\n",
    "\\begin{align}\n",
    "  (b-a) \\to \\tfrac12(b-a) \\to \\tfrac14(b-a) \\to \\cdots\n",
    "\\end{align}\n",
    "\n",
    "After $n$ iterations, the uncertainty in the root is\n",
    "\\begin{align}\n",
    "  \\Delta x_n \\approx \\frac{b-a}{2^n}.\n",
    "\\end{align}\n",
    "\n",
    "Although this convergence \"exponentially\" in terms of number of steps\n",
    "$n$, we do not call this expoential convergence.\n",
    "Instead, \"convergence\" in numerical analysis is usually from a step\n",
    "size, i.e., $b-a$ for bisection method.\n",
    "As $\\Delta x_n$ scales only linear to $b-a$, bisection method is only\n",
    "linear convergence.\n",
    "It is reliable, but slower than other methods that we will introduce\n",
    "later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection(f, a, b, tol=1e-6, imax=100):\n",
    "    if f(a)*f(b) >= 0:\n",
    "        raise ValueError(\"f(a) and f(b) must have opposite signs.\")\n",
    "        \n",
    "    for _ in range(imax):\n",
    "        m = 0.5*(a+b)\n",
    "        if f(m) == 0 or (b-a)/2 < tol:\n",
    "            return m\n",
    "        \n",
    "        if f(a)*f(m) > 0:\n",
    "            a = m\n",
    "        else:\n",
    "            b = m\n",
    "\n",
    "    raise ValueError(\"Maximum iterations reached without convergence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Let's solve $f(x)=x^3−x−2$,\n",
    "which has a root between 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**3 - x - 2\n",
    "\n",
    "root = bisection(f, 1, 2, tol=1e-6)\n",
    "print(\"Approximate root:\", root)\n",
    "print(\"f(root) =\", f(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.linspace(1, 2, 101)\n",
    "Y = f(X)\n",
    "\n",
    "plt.plot(X, Y, label=\"f(x)\")\n",
    "plt.plot(root, f(root), \"o\", label=\"Root\")\n",
    "plt.axhline(0, color=\"black\", lw=1)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "The bisection method is the most robust way to refine a root by\n",
    "repeatedly shrinking the search interval.\n",
    "Because it is so basic, it is one of the algorithm explicitly required\n",
    "by 513!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
