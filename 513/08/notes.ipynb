{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ODE Integrators I: Explicit Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Ordinary differential equations form the mathematical foundation of\n",
    "physics.\n",
    "They describe how systems evolve in time, e.g., Newton's second law of\n",
    "motion is\n",
    "\\begin{align}\n",
    "  f = m a = m \\frac{d^2x}{dt^2},\n",
    "\\end{align}\n",
    "which is a second-order ODE relating force to acceleration.\n",
    "More generally, an ODE relates a function of time to its time\n",
    "derivatives.\n",
    "\n",
    "While ODEs capture the essence of dynamics, analytic solutions are\n",
    "possible only in special cases.\n",
    "Most real systems involve nonlinear forces, damping, or external\n",
    "driving terms that make exact solutions impossible.\n",
    "Numerical integration allows us to approximate trajectories step by\n",
    "step and study systems far beyond what can be solved by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Problem Definition and Types of ODEs\n",
    "\n",
    "Consider two forms of first-order ODEs:\n",
    "\n",
    "1. Time-dependent forcing only:\n",
    "   \\begin{align}\n",
    "     \\frac{dx}{dt} = f(t).\n",
    "   \\end{align}\n",
    "   Here, the derivative depends only on time.\n",
    "   Solutions are obtained by direct integration:\n",
    "   \\begin{align}\n",
    "     x(t) = x(t_0) + \\int_{t_0}^{t} f(t') \\, dt'.\n",
    "   \\end{align}\n",
    "\n",
    "2. State- and time-dependent dynamics:\n",
    "   \\begin{align}\n",
    "     \\frac{dx}{dt} = f(x, t).\n",
    "   \\end{align}\n",
    "   Now, the derivative depends on the state $x$ itself.\n",
    "   The function we want to solve for also appears inside the RHS,\n",
    "   making direct integration impossible.\n",
    "   We cannot evaluate the integral without already knowing $x(t)$ at\n",
    "   intermediate points.\n",
    "\n",
    "The first type reduces to standard numerical quadrature (trapezoidal\n",
    "rule, Simpson's rule, etc.), which we studied earlier.\n",
    "The second case, nonlinear dependence on both $x$ and $t$, is the\n",
    "typical situation in physics.\n",
    "Examples include planetary orbits, nonlinear oscillators, chaotic\n",
    "systems, and interacting biological populations.\n",
    "In such cases:\n",
    "* Direct integration is often not feasible, the problem must be solved\n",
    "  as an initial value problem (IVP).\n",
    "* Analytic solutions are often unknown or intractable.\n",
    "* Numerical methods approximate the solution incrementally, using\n",
    "  small time steps to trace the system's evolution.\n",
    "\n",
    "By discretizing time and advancing step-by-step, we can model the\n",
    "behavior of even the most complex systems.\n",
    "This is the core idea behind numerical ODE integrators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Euler's Method\n",
    "\n",
    "Euler's method is the simplest techniques for numerically solving\n",
    "ordinary differential equations.\n",
    "This method provides an easy way to approximate the solution of an IVP\n",
    "by advancing one small step at a time.\n",
    "\n",
    "We can apply Euler's method to an ODE of the form:\n",
    "\\begin{align}\n",
    "  \\frac{dx}{dt} = f(x, t), \\quad x(t_0) = x_0\n",
    "\\end{align}\n",
    "where $x_0$ is the initial value of $x$ at time $t = t_0$.\n",
    "However, as we will see below, it is usually not recommanded in\n",
    "pratical calculations because of its stability properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Forward (Explicit) Euler Method\n",
    "\n",
    "There are three simple ways to derive Euler's method.\n",
    "The easiest way is simply hold $x$ fixed in $f(x, t)$ and apply the\n",
    "left Reimann sum.\n",
    "The left Reimann sum is first order in step size by approximating\n",
    "$f(x, t)$ as a constant.\n",
    "In this sense, holding $x$ is somewhat \"self-consistent\" in terms of\n",
    "approximation order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "We then recall the definition of a deriviative:\n",
    "\\begin{align}\n",
    "  f(x, t) = \\frac{dx}{dt} = \\lim_{\\Delta t\\rightarrow 0}\\frac{x(t + \\Delta t) - x(t)}{\\Delta t}.\n",
    "\\end{align}\n",
    "If we simply remove the limit and keep the \"finite difference\" part,\n",
    "then it is trivial to show\n",
    "\\begin{align}\n",
    "  x(t + \\Delta t) &\\approx x(t) + f(x(t), t)\\Delta t.\n",
    "\\end{align}\n",
    "Which is nothing but again the forward Euler method.\n",
    "While very intuitive, the above two derivations do not formally show\n",
    "the order of the Euler method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "We may also consider a numerical approximation to the solution of an\n",
    "ODE.\n",
    "We approximate the solution at time $t_{n+1} = t_n + \\Delta t$ by\n",
    "using the Taylor expansion:\n",
    "\\begin{align}\n",
    "  x(t_{n+1}) = x(t_n) + f(x(t_n), t_n) \\Delta t + \\mathcal{O}(\\Delta t^2)\n",
    "\\end{align}\n",
    "Neglecting the higher-order terms in the expansion, we obtain once\n",
    "again the Forward Euler Method:\n",
    "\\begin{align}\n",
    "  x_{n+1} = x_n + f(x_n, t_n) \\Delta t\n",
    "\\end{align}\n",
    "It is thus a step-by-step approach that proceeds by evaluating $f(x,\n",
    "t)$ at each time point and then advancing to the next point.\n",
    "It is an explicit method in 1st order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Let's solve the simple differential equation:\n",
    "\\begin{align}\n",
    "  \\frac{dx}{dt} = \\lambda x(t)\n",
    "\\end{align}\n",
    "\n",
    "This equation has solution\n",
    "\\begin{align}\n",
    "  x(t) = \\exp[\\lambda(t-t_0)]\n",
    "\\end{align}\n",
    "\n",
    "If we choose $\\lambda = 1$ and $x(0) = 1$, the solutoin reduces to\n",
    "$x(t) = \\exp(t)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the solution:\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "T = np.linspace(0, 2, 201)\n",
    "X = np.exp(T)\n",
    "\n",
    "plt.plot(T, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's implement Euler's method, with history\n",
    "\n",
    "def Euler(f, x, t, dt, n):\n",
    "    X = [np.array(x)]\n",
    "    T = [np.array(t)]\n",
    "    for _ in range(n):\n",
    "        X.append(X[-1] + dt * f(X[-1]))\n",
    "        T.append(T[-1] + dt)\n",
    "    return np.array(X), np.array(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test Euler's method\n",
    "\n",
    "f = lambda x: x\n",
    "\n",
    "X1, T1 = Euler(f, 1, 0, 0.1, 20)\n",
    "\n",
    "plt.plot(T, X)\n",
    "plt.plot(T1, X1, 'o-')\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As always, we can study the convergence of the numerical method\n",
    "\n",
    "def Err1(N=200):\n",
    "    X1, T1 = Euler(f, 1, 0, 2/N, N)\n",
    "    X = np.exp(T1)\n",
    "    return np.max(abs(X1 - X))\n",
    "\n",
    "N  = np.array([64, 128, 256, 512, 1024])\n",
    "E1 = np.array([Err1(n) for n in N])\n",
    "\n",
    "plt.loglog(N, 16/N, label='1/N')\n",
    "plt.loglog(N, E1, 'o:', label='Forward Euler')\n",
    "plt.xlabel('N')\n",
    "plt.ylabel(r'$\\text{err} = \\max|x_\\text{numeric} - x|$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### System of ODEs\n",
    "\n",
    "In computational astrophysics, we often encounter systems governed by\n",
    "Newton's laws:\n",
    "\\begin{align}\n",
    "  m \\frac{d^2 x}{dt^2} = f(x, t)\n",
    "\\end{align}\n",
    "\n",
    "This equation is a second-order ordinary differential equation because\n",
    "it involves the second derivative of $x$ with respect to $t$.\n",
    "However, it is often more practical to convert second-order ODEs into\n",
    "a system of first-order ODEs.\n",
    "To do this, we introduce a new variable, $v = dx/dt$, representing the\n",
    "velocity of the object.\n",
    "This substitution allows us to rewrite the second-order ODE as two\n",
    "coupled first-order ODEs:\n",
    "\\begin{align}\n",
    "  \\frac{dx}{dt} &= v \\\\\n",
    "  \\frac{dv}{dt} &= \\frac{1}{m}f(x, t)\n",
    "\\end{align}\n",
    "\n",
    "This formulation provides a convenient way for numerical methods,\n",
    "which are generally well-suited to solving systems of first-order\n",
    "ODEs.\n",
    "To further simplify, we can express these equations in vector notation\n",
    "by defining $\\mathbf{x} = [x, v]^t$ and $\\mathbf{f} = [v, f/m]^t$.\n",
    "The system then becomes:\n",
    "\\begin{align}\n",
    "  \\frac{d\\mathbf{x}}{dt} = \\mathbf{f}(\\mathbf{x}, t).\n",
    "\\end{align}\n",
    "This vector form emphasizes the structure of the system and enables us\n",
    "to apply general numerical techniques to solve both equations\n",
    "simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "To illustrate this approach, let's consider a classic example: the\n",
    "simple pendulum under gravity.\n",
    "The motion of a pendulum of length $l$, swinging under gravity $g$,\n",
    "can be described by the second-order equation:\n",
    "\\begin{align}\n",
    "  \\frac{d^2\\theta}{dt^2} + \\frac{g}{l} \\sin\\theta = 0\n",
    "\\end{align}\n",
    "\n",
    "Here, $\\theta(t)$ is the angle of the pendulum with the vertical, and\n",
    "the term $\\sin \\theta$ introduces nonlinearity, which makes the\n",
    "equation challenging to solve analytically.\n",
    "Converting this equation into a system of first-order ODEs allows us\n",
    "to handle it more effectively with numerical methods.\n",
    "We define $\\Omega = \\frac{d\\theta}{dt}$, the angular velocity, leading\n",
    "to the following system:\n",
    "\\begin{align}\n",
    "  \\frac{d\\theta(t)}{dt} &= \\Omega(t)\\\\\n",
    "  \\frac{d\\Omega(t)}{dt} &= - \\frac{g}{l}\\sin\\theta(t)\n",
    "\\end{align}\n",
    "\n",
    "In vector notation, we represent the system as:\n",
    "\\begin{align}\n",
    "  \\frac{d\\mathbf{x}(t)}{dt} = \\mathbf{f}(\\mathbf{x}, t)\n",
    "\\end{align}\n",
    "where\n",
    "\\begin{align}\n",
    "  \\mathbf{x} &= \\begin{bmatrix} \\theta(t) \\\\ \\Omega(t) \\end{bmatrix}, \\\\\n",
    "  \\mathbf{f}(\\mathbf{x}, t) &= \\begin{bmatrix} \\Omega(t) \\\\ -\\frac{g}{l} \\sin \\theta(t) \\end{bmatrix}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "In later part of the lecture, we will try to solve this full problem.\n",
    "But to derive and compare different numerical methods, let's first\n",
    "reduce the problem to something that has analytical solutions.\n",
    "Specifically, we can simplify the pendulum problem further by assuming\n",
    "small oscillations, where the angle $\\theta$ is small enough that\n",
    "$\\sin \\theta \\approx \\theta$.\n",
    "This approximation linearizes the equation of motion, reducing the\n",
    "system to a simple harmonic oscillator.\n",
    "\n",
    "In this approximation, the equation of motion becomes:\n",
    "\\begin{align}\n",
    "  \\frac{d^2 \\theta}{dt^2} + \\frac{g}{l} \\theta = 0\n",
    "\\end{align}\n",
    "As a result, the system of ODEs becomes:\n",
    "\\begin{align}\n",
    "  \\mathbf{x} &= \\begin{bmatrix} \\theta(t) \\\\ \\Omega(t) \\end{bmatrix}, \\\\\n",
    "  \\mathbf{f}(\\mathbf{x}, t) &= \\begin{bmatrix} \\Omega(t) \\\\ -\\frac{g}{l} \\theta(t) \\end{bmatrix}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first plot the analytical solution\n",
    "\n",
    "T     = np.linspace(0, 10, 101)\n",
    "Theta = 0.01 * np.sin(T)\n",
    "\n",
    "plt.plot(T, Theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to operator overriding, our forward Euler method is almost\n",
    "# ready to solve system of ODEs!\n",
    "# There is no need to rewrite it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the analytical and numerical solutions\n",
    "\n",
    "def F(x):\n",
    "    theta, omega = x\n",
    "    return np.array([omega, -theta])\n",
    "\n",
    "X1, T1 = Euler(F, [0.0, 0.01], 0, 0.01, 1000)\n",
    "\n",
    "Theta1 = X1[:,0]\n",
    "Omega1 = X1[:,1]\n",
    "\n",
    "plt.plot(T,  Theta)\n",
    "plt.plot(T1, Theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, we can study the convergence of the numerical method\n",
    "\n",
    "def Err(integrator, N=100, **kwargs):\n",
    "    Xf, Tf = integrator(F, [0, 0.01], 0, 10/N, N, **kwargs)\n",
    "    Thetaf = Xf[:,0]\n",
    "    Theta  = 0.01 * np.sin(Tf)\n",
    "    return np.max(abs(Thetaf - Theta))\n",
    "\n",
    "N  = np.array([64, 128, 256, 512, 1024])\n",
    "E1 = np.array([Err(Euler, n) for n in N])\n",
    "\n",
    "plt.loglog(N, 0.5/N, label='1/N')\n",
    "plt.loglog(N, E1, 'o:', label='Forward Euler')\n",
    "plt.xlabel('N')\n",
    "plt.ylabel(r'$\\text{err} = \\max|x_\\text{numeric} - x|$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### A Midpoint Method?\n",
    "\n",
    "The Forward Euler method is only first-order accurate, meaning its\n",
    "error decreases linearly with the step size $\\Delta t$, as we saw in\n",
    "the convergence plots.\n",
    "While it is simple to implement, this method's convergence rate is\n",
    "too slow.\n",
    "Achieving higher accuracy requires very small steps, which can become\n",
    "computationally expensive.\n",
    "\n",
    "This naturally raises the question: can we improve the convergence\n",
    "rate of our numerical solution, reducing the error more rapidly as we\n",
    "use smaller steps?\n",
    "\n",
    "To explore this, we can draw inspiration from our previous work on\n",
    "numerical integration.\n",
    "In that context, we observed that the midpoint (or central) Riemann\n",
    "sum converges faster than the left or right Riemann sums.\n",
    "This suggests that a midpoint approach may also provide advantages in\n",
    "solving ODEs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "One possible improvement is to propose a midpoint method that attempts\n",
    "to evaluate the function $\\mathbf{f}$ at the midpoint between steps.\n",
    "Mathematically, this approach can be expressed as:\n",
    "\\begin{align}\n",
    "  \\mathbf{x}_{n+1} = \\mathbf{x}_n + \\mathbf{f}(\\mathbf{x}_{n+1/2}, t_{n+1/2}) \\Delta t\n",
    "\\end{align}\n",
    "\n",
    "However, a significant problem arises: the midpoint value $f_{n+1/2}\n",
    "\\equiv f(\\mathbf{x}_{n+1/2}, t_{n+1/2})$ is unknown at step $n$.\n",
    "We need to know the value of $\\mathbf{x}$ at the midpoint $t_{n+1/2}$\n",
    "to use this method, but this value cannot be calculated without\n",
    "already knowing the future values of $\\mathbf{x}$.\n",
    "This issue makes a straightforward midpoint method impractical for\n",
    "generic ODEs, where $\\mathbf{f}$ depends on both $\\mathbf{x}$ and $t$.\n",
    "\n",
    "An exception occurs if $\\mathbf{f}$ depends only on $t$, as in\n",
    "$\\frac{dx}{dt} = f(t)$; in such cases, a true midpoint method is\n",
    "feasible, which is nothing but out middle Reimann sum.\n",
    "However, for most ODEs, including those where $\\mathbf{f}$ depends on\n",
    "$\\mathbf{f}$, a different approach is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### A Simple Idea: The Second-Order Runge-Kutta Method\n",
    "\n",
    "To work around this issue, we can approximate the midpoint value\n",
    "instead of calculating it exactly.\n",
    "It suffices to find an approximate solution for $\\mathbf{x}$ at the\n",
    "half-step, which we denote as $\\mathbf{x}_{n+1/2}$.\n",
    "\n",
    "The simplest way to do this is to use the Forward Euler method to\n",
    "compute an estimated value at the midpoint.\n",
    "Specifically, we can approximate $\\mathbf{x}$ at $t_{n+1/2}$ as:\n",
    "\\begin{align}\n",
    "  \\tilde{\\mathbf{x}}_{n+1/2} = \\mathbf{x}_n + \\mathbf{f}(\\mathbf{x}_n, t_n) \\frac{\\Delta t}{2}\n",
    "\\end{align}\n",
    "Using this half-step approximation, we then proceed with a full step\n",
    "to find $\\mathbf{x}_{n+1}$ by evaluating $f$ at the midpoint:\n",
    "\\begin{align}\n",
    "  \\mathbf{x}_{n+1} = \\mathbf{x}_n + f(\\tilde{\\mathbf{x}}_{n+1/2}, t_{n+1/2}) \\Delta t\n",
    "\\end{align}\n",
    "This approach, known as the second-order Runge-Kutta method,\n",
    "incorporates midpoint information and achieves second-order accuracy.\n",
    "\n",
    "This second-order Runge-Kutta method improves convergence by\n",
    "leveraging an approximate midpoint, resulting in a more accurate\n",
    "solution than the first-order Euler method without prohibitively small\n",
    "step size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RK2(f, x, t, dt, n):\n",
    "    X = [np.array(x)]\n",
    "    T = [np.array(t)]\n",
    "    for _ in range(n):\n",
    "        k1 = f(X[-1])\n",
    "        xh = X[-1] + 0.5 * dt * k1\n",
    "        \n",
    "        k2 = f(xh)\n",
    "        xf = X[-1] + dt * k2\n",
    "        \n",
    "        X.append(xf)\n",
    "        T.append(T[-1] + dt)\n",
    "    return np.array(X), np.array(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=64\n",
    "X2, T2 = RK2(F, [0, 0.01], 0, 10/N, N)\n",
    "plt.plot(T, 0.01 * np.sin(T))\n",
    "plt.plot(T2, X2[:,0], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Euler(f, x, t, dt, n, substep=1):\n",
    "    if substep == 1:  # the above forward Euler\n",
    "        X = [np.array(x)]\n",
    "        T = [np.array(t)]\n",
    "        for _ in range(n):\n",
    "            X.append(X[-1] + dt * f(X[-1]))\n",
    "            T.append(T[-1] + dt)\n",
    "        return np.array(X), np.array(T)\n",
    "    else:\n",
    "        X, T = Euler(f, x, t, dt/substep, n*substep)\n",
    "        return X[::substep], T[::substep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=64\n",
    "X1, T1 = Euler(F, [0, 0.01], 0, 10/N, N, substep=2)\n",
    "plt.plot(T, 0.01 * np.sin(T))\n",
    "plt.plot(T1, X1[:,0], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, we can study the convergence of the numerical method\n",
    "\n",
    "N   = np.array([64, 128, 256, 512, 1024])\n",
    "E1  = np.array([Err(Euler, n)            for n in N])\n",
    "E12 = np.array([Err(Euler, n, substep=2) for n in N])\n",
    "E2  = np.array([Err(RK2,   n)            for n in N])\n",
    "\n",
    "plt.loglog(N, 0.5/N, label='1/N')\n",
    "plt.loglog(N, E1,  'o:', label='Forward Euler')\n",
    "plt.loglog(N, E12, 'o-', label='Substep Euler')\n",
    "plt.loglog(N, E2,  'o-', label='RK2')\n",
    "\n",
    "plt.xlabel('N')\n",
    "plt.ylabel(r'$\\text{err} = \\max|x_\\text{numeric} - x|$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "The convergence plot clearly demonstrates that RK2 achieves\n",
    "second-order accuracy.\n",
    "This means that the error decreases quadratically with the step size\n",
    "$\\Delta t$.\n",
    "For example, using 1024 points for the integration not only doubles\n",
    "the computational cost compared to using 512 points but also improves\n",
    "the accuracy of the solution by approximately 250 times.\n",
    "This significant increase in accuracy suggests that higher-order\n",
    "methods offer substantial benefits, especially for problems requiring\n",
    "high precision.\n",
    "Naturally, this brings us to the question: can we improve the accuracy\n",
    "even further than what RK2 provides?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
