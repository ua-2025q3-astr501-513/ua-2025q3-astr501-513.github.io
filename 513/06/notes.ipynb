{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Numerical Integration of Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "In science and engineering, many important quantities are obtained by\n",
    "integrating functions.\n",
    "Examples include the total energy radiated by a star (integral of\n",
    "brightness over wavelength),\n",
    "the probability of finding a quantum particle in a region (integral of\n",
    "probability density), or\n",
    "the synchrotron emissivity function (integral over electron\n",
    "distribution function).\n",
    "\n",
    "Analytical solutions are rare because real functions often come from\n",
    "measurements, simulations, or complicated models.\n",
    "In such cases, we rely on **numerical integration** (or *quadrature*)\n",
    "to approximate\n",
    "\\begin{align}\n",
    "  I = \\int_a^b f(x)\\,dx,\n",
    "\\end{align}\n",
    "using only a finite number of function evaluations.\n",
    "\n",
    "Numerical integration provides a controlled setting to study how\n",
    "approximations are constructed, how accuracy depends on step size, and\n",
    "how errors accumulate.\n",
    "These lessons generalize directly to solving differential equations\n",
    "and more complex simulations, making integration an essential starting\n",
    "point for good numerical practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "To study numerical integration systematically, it helps to begin with\n",
    "a function whose integral we know exactly.\n",
    "Consider $f(x) = e^x$.\n",
    "Its definite integral from $a$ to $b$ is\n",
    "\\begin{align}\n",
    "  I = \\int_a^b e^x \\, dx = e^b - e^a.\n",
    "\\end{align}\n",
    "On the interval $[0,1]$, the exact value is $I = e - 1$.\n",
    "This known result will allow us to check the accuracy of numerical\n",
    "approximations as we vary step size and method.\n",
    "\n",
    "Below is a simple plot of $f(x)=e^x$ on $[0,1]$ for visual reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def f(x):\n",
    "    return np.exp(x)\n",
    "\n",
    "# Define a fine grid for plotting\n",
    "X = np.linspace(0, 1, 1025)\n",
    "Y = f(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(X, Y, label=r\"$f(x) = e^x$\")\n",
    "plt.fill_between(X, Y, alpha=1/3, label=r'$I = \\int_a^b f(x) dx$')\n",
    "plt.title(r'Function $f(x) = e^x$ on $[0,1]$')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Riemann Sums\n",
    "\n",
    "In undergraduate calculus, we learn the integral as the limit of\n",
    "Riemann sums:\n",
    "\\begin{align}\n",
    "  \\int_a^b f(x) dx\n",
    "  \\equiv \\lim_{n \\to \\infty} \\sum_{i=1}^n f(x_i) \\Delta x,\n",
    "\\end{align}\n",
    "where $\\Delta x \\equiv (b-a)/n$.\n",
    "\n",
    "In **numerical analysis**, however, we do **not** take the limit.\n",
    "Instead, we keep the division of $[a, b]$ into $n$ subintervals and\n",
    "use\n",
    "\\begin{align}\n",
    "  I \\approx \\sum_{i=1}^n f(x_i)\\,\\Delta x,\n",
    "\\end{align}\n",
    "as a practical approximation.\n",
    "The choice of sampling point $x_i$ determines the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Common choices for $x_i$ give us three variants:\n",
    "* Left Riemann Sum: $x_i$ is the left endpoint.\n",
    "* Right Riemann Sum: $x_i$ is the right endpoint.\n",
    "* Midpoint (or middle) Riemann Sum: $x_i$ is the midpoint.\n",
    "\n",
    "```{note} Analogy with Finite Differences\n",
    "\n",
    "Just as we approximated derivatives using forward, backward, and\n",
    "central differences,\n",
    "\n",
    "Riemann sums mirror this structure:\n",
    "* Left Riemann $\\leftrightarrow$ forward difference\n",
    "* Right Riemann $\\leftrightarrow$ backward difference\n",
    "* Midpoint Riemann $\\leftrightarrow$ central difference\n",
    "\n",
    "In derivatives, these approximations predict slopes.\n",
    "In integrals, they approximate accumulated areas.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n  = 8  # number of intervals\n",
    "dx = 1 / n\n",
    "\n",
    "Xl = np.linspace(0, 1-dx, n)\n",
    "Xm = np.linspace(dx/2, 1-dx/2, n)\n",
    "Xr = np.linspace(dx, 1, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(12,4), sharey=True)\n",
    "\n",
    "# Left Riemann Sum\n",
    "for ax, Xs, name in zip(axes, [Xl, Xm, Xr], ['Left', 'Middle', 'Right']):\n",
    "    Ys = f(Xs)\n",
    "    ax.plot(X, Y)\n",
    "    ax.bar(Xm, Ys, width=dx, align='center', color='C1', edgecolor=None, alpha=1/3)\n",
    "    ax.scatter(Xs, Ys, color='C1', zorder=10)\n",
    "    ax.set_title(f'{name} Riemann Sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: There is another to define the middle Reimann sun,\n",
    "#          where the sample points are \"on vertex \", i.e.,\n",
    "#          $x_i = a + (b-a) (i/n)$ for $i = 0, ..., n$.\n",
    "#          What is the different between this definition and ours?\n",
    "#          From the plots, what do you think about the relationships\n",
    "#          between left, right, and this new middle Reimann sums?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Computing Riemann Sums\n",
    "\n",
    "Now that we have defined the left, right, and midpoint Riemann sums,\n",
    "let us implement them and check their accuracy against the exact\n",
    "result\n",
    "\\begin{align}\n",
    "  I = \\int_0^1 e^x \\, dx = e - 1.\n",
    "\\end{align}\n",
    "\n",
    "We begin with a simple case using $N=8$ subintervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = np.e - 1\n",
    "\n",
    "print(f\"         Exact value: {I :.8f}\")\n",
    "\n",
    "for ax, Xs, name in zip(axes, [Xl, Xm, Xr], ['Left', 'Middle', 'Right']):\n",
    "    S = np.sum(f(Xs)) * dx  # multiple dx after sum\n",
    "    print(f\"{name:>8} Riemann Sum: {S:.8f}, error = {abs(I - S):.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: try increasing $n$ and then observe the errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "As the number of subintervals $n$ increases, all three Riemann sums\n",
    "converge toward the exact value $e-1$.\n",
    "However, the midpoint rule generally gives much better accuracy for\n",
    "the same $n$, just as central differences are more accurate than\n",
    "forward or backward differences.\n",
    "This shows how the choice of sample points directly affects accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Convergence of Riemann Sums\n",
    "\n",
    "In numerical analysis, as we saw in earlier lecture, convergence means\n",
    "studying how the error decreases as we refine the discretization.\n",
    "For integration, we ask how does the error behave as we increase the\n",
    "number of subintervals $n$?\n",
    "\n",
    "To make comparisons easier, let's define a general function for\n",
    "computing Riemann sums of any type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RiemannSum(f, n=8, a=0, b=1, method='mid'):\n",
    "    dx = (b-a)/n\n",
    "    hx = dx/2\n",
    "    \n",
    "    if method.startswith('l'):\n",
    "        X = np.linspace(a,    b-dx, n)  # left endpoints\n",
    "    elif method.startswith('r'):\n",
    "        X = np.linspace(a+dx, b,    n)  # right endpoints\n",
    "    else:\n",
    "        X = np.linspace(a+hx, b-hx, n)  # midpoints\n",
    "    \n",
    "    return np.sum(f(X)) * dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Now we can study convergence systematically by increasing $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convergence(f, N, I):\n",
    "    # Compute absolute errors for each method\n",
    "    El = [abs(RiemannSum(f, n, method='l') - I) for n in N]\n",
    "    Em = [abs(RiemannSum(f, n, method='m') - I) for n in N]\n",
    "    Er = [abs(RiemannSum(f, n, method='r') - I) for n in N]\n",
    "\n",
    "    # Plot convergence behavior\n",
    "    plt.loglog(N, El, 'o-',  label='Left Riemann Sum')\n",
    "    plt.loglog(N, Em, '^--', label='Middle Riemann Sum')\n",
    "    plt.loglog(N, Er, 's:',  label='Right Riemann Sum')\n",
    "\n",
    "    # Reference slopes\n",
    "    plt.loglog(N, 1.2e+0 / N,    ':', lw=1, label=r'$n^{-1}$')\n",
    "    plt.loglog(N, 1.0e-1 / N**2, ':', lw=1, label=r'$n^{-2}$')\n",
    "\n",
    "    plt.xlabel('Number of Subintervals $n$')\n",
    "    plt.ylabel('Absolute Error')\n",
    "    plt.title('Convergence of Riemann Sums')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2**np.arange(2,11)  # range of sample sizes\n",
    "convergence(f, N, np.e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "From the plot, we observe:\n",
    "* Left and Right Riemann sums converge at roughly a rate\n",
    "  $\\sim N^{-1}$.\n",
    "* Midpoint Riemann sum converges faster, at a rate closer to\n",
    "  $\\sim N^{-2}$.\n",
    "\n",
    "This higher order of accuracy explains why the midpoint method is much\n",
    "more accurate for the same number of intervals.\n",
    "The pattern mirrors what we saw with finite differences: forward and\n",
    "backward methods are first-order accurate, while central methods are\n",
    "second-order accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Testing Convergence with Different Functions\n",
    "\n",
    "To determine if this trend holds generally, let's repeat the\n",
    "convergence test with different functions:\n",
    "a half-cycle of $\\sin[(\\pi/2)(1-x)]$ and\n",
    "a quarter circle $\\sqrt{1-x^2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = lambda x: np.sin((np.pi/2) * (1-x))\n",
    "f3 = lambda x: np.sqrt(1 - x*x)\n",
    "\n",
    "plt.plot(X, f2(X))\n",
    "plt.plot(X, f3(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence(f2, N, 2/np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence(f3, N, np.pi/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: why does Middle Riemann Sum not converge as expected for\n",
    "#          quarter circle?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Although the formal convergence rates hold in general, special\n",
    "functions (e.g. highly oscillatory or discontinuous ones) may behave\n",
    "differently.\n",
    "Understanding these exceptions is a key part of numerical analysis.\n",
    "\n",
    "As we progress, we will adopt the notation and framework used in\n",
    "Numerical Recipes and related references.\n",
    "These general-purpose methods extend the ideas of Riemann sums to more\n",
    "accurate and flexible quadrature formulas, allowing us to tackle\n",
    "realistic integration problems efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Classical Formulas for Equally Spaced Abscissas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Trapezoidal Rule\n",
    "\n",
    "To move beyond Riemann sums, we now consider the trapezoidal rule, one\n",
    "of the most widely used numerical integration formulas.\n",
    "\n",
    "From here on, we adopt the vertex formulation:\n",
    "\\begin{align}\n",
    "  x_i = a + i \\Delta x,\n",
    "  \\quad \\Delta x = \\frac{b-a}{n},\n",
    "  \\quad i=0,1,\\dots,n.\n",
    "\\end{align}\n",
    "\n",
    "The trapezoidal rule approximates the area under a curve by replacing\n",
    "each subinterval with a trapezoid.\n",
    "For a single interval $[x_i, x_{i+1}]$ with width $h = x_{i+1} - x_i$,\n",
    "we have:\n",
    "\\begin{align}\n",
    "  \\int_{x_i}^{x_{i+1}} f(x) dx\n",
    "  \\approx \\frac{h}{2}\\left[f(x_i) + f(x_{i+1})\\right].\n",
    "\\end{align}\n",
    "\n",
    "The error for one interval is of order $\\mathcal{O}(h^3 f'')$, which\n",
    "means the global error (after $n$ intervals) is $\\mathcal{O}(h^2)$.\n",
    "This makes the trapezoidal rule second-order accurate.\n",
    "If $f(x)$ is linear (so $f''=0$), the approximation is exact.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function: quarter circle\n",
    "Y = f(X)\n",
    "\n",
    "# Plot with a coarse trapezoidal partition\n",
    "n  = 4\n",
    "Xt = np.linspace(0, 1, n+1)\n",
    "Yt = f(Xt)\n",
    "\n",
    "plt.plot(X, Y, label=r\"$f(x) = \\sqrt{1-x^2}$\")\n",
    "plt.scatter(Xt, Yt, color='C1')\n",
    "plt.bar(Xt, Yt, width=Xt[1]-Xt[0], align='center',\n",
    "        color='C1', edgecolor=None, alpha=1/3, label='Middle Riemann Sum')\n",
    "plt.fill_between(Xt, Yt,\n",
    "                 color='C2', alpha=1/3, label='Trapezoidal Rule')\n",
    "\n",
    "plt.xlim(0, 1)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: look at the figure carefully.\n",
    "#          What is the result from the Middle Riemann Sum (on vertex)\n",
    "#          compared to the trapezoidal rule?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: reformulate the trapezoidal rule to speed it up.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
