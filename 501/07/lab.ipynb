{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Parallel Computing, HPC, and Slurm [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ua-2025q3-astr501-513/ua-2025q3-astr501-513.github.io/blob/main/501/07/lab.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Modern scientific research, from simulating black holes to modeling\n",
    "climate systems, requires computational resources that far exceed what\n",
    "a single processor can provide.\n",
    "Problems involving massive datasets or computationally expensive\n",
    "algorithms (e.g., Monte Carlo simulations, numerical PDE solvers,\n",
    "machine learning training) demand performance beyond sequential\n",
    "execution.\n",
    "\n",
    "Parallel computing addresses this by breaking a problem into smaller\n",
    "tasks that can be solved simultaneously on multiple processing\n",
    "elements.\n",
    "With the rise of multicore CPUs, distributed systems, GPUs, and\n",
    "specialized accelerators, parallel computing has become central to\n",
    "high-performance computing (HPC).\n",
    "This lab will introduce you to the theory, programming models, and\n",
    "practical execution of parallel codes, with examples in Python, C, and\n",
    "MPI.\n",
    "You will also gain experience running jobs on a modern HPC cluster\n",
    "with a workload manager like Slurm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Theoretical Foundations\n",
    "\n",
    "Before we dive into implementation, we review key concepts that define\n",
    "the limits and opportunities of parallelism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Amdahl's Law (Strong Scaling)\n",
    "\n",
    "If a fraction $f$ of a program is inherently sequential, the maximum\n",
    "speedup $P$ with $P$ processors is:\n",
    "\\begin{align}\n",
    "  S(P) = \\frac{1}{f + (1-f)/P}.\n",
    "\\end{align}\n",
    "Note that, as $P \\to \\infty$, $S \\to 1/f$.\n",
    "\n",
    "Implication: Even a small sequential portion limits total speedup.\n",
    "* Example: If 5% of your code is sequential, the maximum speedup is\n",
    "  20x, no matter how many processors you add.\n",
    "* This highlights why HPC algorithms for systems like Frontier (the\n",
    "  DOE exascale machine) must minimize sequential bottlenecks.\n",
    "\n",
    "This corresponds to strong scaling tests, where the problem size is\n",
    "fixed and we ask how performance improves as resources increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Gustafson's Law (Weak Scaling)\n",
    "\n",
    "A more optimistic view: as we increase $P$, we also increase the\n",
    "problem size to fully utilize resources:\n",
    "\\begin{align}\n",
    "  S(P) = f + (1-f)P.\n",
    "\\end{align}\n",
    "\n",
    "Implication: In scientific computing, we often want higher resolution\n",
    "or larger domains, so performance scales with problem size.\n",
    "\n",
    "This corresponds to weak scaling tests, which measure how performance\n",
    "changes when the workload grows proportionally with resources."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
