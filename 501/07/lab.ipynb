{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Parallel Computing, HPC, and Slurm [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ua-2025q3-astr501-513/ua-2025q3-astr501-513.github.io/blob/main/501/07/lab.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Modern scientific research, from simulating black holes to modeling\n",
    "climate systems, requires computational resources that far exceed what\n",
    "a single processor can provide.\n",
    "Problems involving massive datasets or computationally expensive\n",
    "algorithms (e.g., Monte Carlo simulations, numerical PDE solvers,\n",
    "machine learning training) demand performance beyond sequential\n",
    "execution.\n",
    "\n",
    "Parallel computing addresses this by breaking a problem into smaller\n",
    "tasks that can be solved simultaneously on multiple processing\n",
    "elements.\n",
    "With the rise of multicore CPUs, distributed systems, GPUs, and\n",
    "specialized accelerators, parallel computing has become central to\n",
    "high-performance computing (HPC).\n",
    "This lab will introduce you to the theory, programming models, and\n",
    "practical execution of parallel codes, with examples in Python, C, and\n",
    "MPI.\n",
    "You will also gain experience running jobs on a modern HPC cluster\n",
    "with a workload manager like Slurm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Theoretical Foundations\n",
    "\n",
    "Before we dive into implementation, we review key concepts that define\n",
    "the limits and opportunities of parallelism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Amdahl's Law (Strong Scaling)\n",
    "\n",
    "If a fraction $f$ of a program is inherently sequential, the maximum\n",
    "speedup $P$ with $P$ processors is:\n",
    "\\begin{align}\n",
    "  S(P) = \\frac{1}{f + (1-f)/P}.\n",
    "\\end{align}\n",
    "Note that, as $P \\to \\infty$, $S \\to 1/f$.\n",
    "\n",
    "Implication: Even a small sequential portion limits total speedup.\n",
    "* Example: If 5% of your code is sequential, the maximum speedup is\n",
    "  20x, no matter how many processors you add.\n",
    "* This highlights why HPC algorithms for systems like Frontier (the\n",
    "  DOE exascale machine) must minimize sequential bottlenecks.\n",
    "\n",
    "This corresponds to strong scaling tests, where the problem size is\n",
    "fixed and we ask how performance improves as resources increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Gustafson's Law (Weak Scaling)\n",
    "\n",
    "A more optimistic view: as we increase $P$, we also increase the\n",
    "problem size to fully utilize resources:\n",
    "\\begin{align}\n",
    "  S(P) = f + (1-f)P.\n",
    "\\end{align}\n",
    "\n",
    "Implication: In scientific computing, we often want higher resolution\n",
    "or larger domains, so performance scales with problem size.\n",
    "\n",
    "This corresponds to weak scaling tests, which measure how performance\n",
    "changes when the workload grows proportionally with resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Flynn's Taxonomy\n",
    "\n",
    "To better understand computing architectures, \n",
    "[Flynn (1972)](https://en.wikipedia.org/wiki/Flynn%27s_taxonomy)\n",
    "classified them into four categories:\n",
    "* SISD:\n",
    "  Single Instruction, Single Data (traditional CPU execution)\n",
    "* SIMD:\n",
    "  Single Instruction, Multiple Data (vector units, GPUs, NumPy and JAX\n",
    "  vectorization if hardware supported)\n",
    "* MISD:\n",
    "  Multiple Instruction, Single Data (rare, mostly theoretical)\n",
    "* MIMD:\n",
    "  Multiple Instruction, Multiple Data (clusters, multicore CPUs,\n",
    "  distributed MPI systems)\n",
    "\n",
    "Programming models map naturally onto these:\n",
    "* [OpenMP](https://www.openmp.org/):\n",
    "  shared-memory SIMD/MIMD\n",
    "* [CUDA](https://en.wikipedia.org/wiki/CUDA)/[OpenCL](https://www.khronos.org/opencl/):\n",
    "  SIMD execution on GPUs\n",
    "* [MPI](https://en.wikipedia.org/wiki/Message_Passing_Interface):\n",
    "  distributed-memory MIMD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Additional Resources\n",
    "\n",
    "* HPC Carpentry lessons:\n",
    "  https://hpc-carpentry.github.io\n",
    "* MPI Tutorial:\n",
    "  https://mpitutorial.com/\n",
    "* Slurm quick-start guide:\n",
    "  https://slurm.schedmd.com/quickstart.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Monte Carlo Computation of $\\pi$\n",
    "\n",
    "We will parallelize a simple algorithm using different techniques.\n",
    "The algorithm is monte carlo computation of $\\pi$.\n",
    "This is an embarrassingly parallel problem.  so not much actual\n",
    "algorithm consideration is needed.\n",
    "We mainly use it to get ourselve familiar with different tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Python Series Code\n",
    "\n",
    "Here is the algorithm in native python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def mcpi_loop(n_total):\n",
    "    n_inside = 0\n",
    "    for _ in range(n_total):\n",
    "        x, y = random.random(), random.random()\n",
    "        if x*x + y*y < 1.0:\n",
    "            n_inside += 1\n",
    "    return n_inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = 4 * mcpi_loop(1000_000) / 1000_000\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit mcpi_loop(1000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "On my laptop it takes about 80ms to perform 1M samples.\n",
    "The number of significant digits is $\\sim \\log_{10}\\sqrt{N} = 3$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Embarrassingly Parallel Computing\n",
    "\n",
    "Since this algorithm is embarrassingly parallelizable, we can simply\n",
    "run it multiple times and compute the mean.\n",
    "Let's do this as a class exercise using this\n",
    "[Google Sheet](https://docs.google.com/spreadsheets/d/11h8p5dsJzD8vCcgBBvA4B0RC2oWzuWjT2HLnogf9nlc/edit?gid=245417564#gid=245417564).\n",
    "\n",
    "Effectively, we just did a weak scaling test!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Numpy Parallel Code\n",
    "\n",
    "When compiled with BLAS backend, `Numpy` automatically distribute\n",
    "compute across multiple cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.__config__.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.environ.get('OPENBLAS_NUM_THREADS', 0))\n",
    "print(os.environ.get('MKL_NUM_THREADS',      0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcpi_numpy(n_total):\n",
    "    x = np.random.rand(n_total)\n",
    "    y = np.random.rand(n_total)\n",
    "    return np.sum(x*x + y*y < 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = 4 * mcpi_numpy(1000_000) / 1000_000\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit mcpi_numpy(1000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MKL_NUM_THREADS']      = '1'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "%timeit mcpi_numpy(1000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MKL_NUM_THREADS']      = '4'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '4'\n",
    "%timeit mcpi_numpy(1000_000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
