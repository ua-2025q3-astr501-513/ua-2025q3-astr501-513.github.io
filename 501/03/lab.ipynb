{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Make, Workflow, and GitHub Action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Modern computational astrophysics is no longer just about interacting\n",
    "with the terminal or writing one-off scripts that generate plots or\n",
    "results.\n",
    "Research projects involve complex pipelines:\n",
    "*i*) generating synthetic data,\n",
    "*ii*) calibrating instruments,\n",
    "*iii*) analyzing observations,\n",
    "*iv*) running simulations, and\n",
    "*v*) producing figures and papers.\n",
    "Each step depends on the outputs of earlier steps.\n",
    "And the whole chain may need to be repeated when code changes, new\n",
    "data arrive, or collaborators join the project.\n",
    "Without systematic management, such workflows quickly become fragile,\n",
    "error-prone, and difficult to reproduce."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Workflow management and automation tools address these challenges.\n",
    "They allow us to:\n",
    "* Capture dependencies:\n",
    "  make sure each step runs only when its inputs are ready.\n",
    "* Avoid redundant work:\n",
    "  rebuild only the outputs affected by changes.\n",
    "* Scale up easily:\n",
    "  run dozens or thousands of jobs in parallel on HPC or the cloud.\n",
    "* Enable reproducibility:\n",
    "  capture all the steps needed to regenerate results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "In practice, we often combine several layers of automation:\n",
    "\n",
    "* `make`:\n",
    "  lightweight automation for compiling code, running tests, build\n",
    "  documentations, and chaining a few steps together.\n",
    "  `Make` has been around for decades and remains a powerful tool for\n",
    "  small pipelines.\n",
    "* Workflow engines (such as `Snakemake`):\n",
    "  generalizations of `make` that make it easy to run large-scale\n",
    "  scientific workflows in parallel, track provenance, and use portable\n",
    "  environments.\n",
    "* Continuous Integration / Continuous Deployment (CI/CD):\n",
    "  services such as *GitHub Actions* that automatically run tests,\n",
    "  build documentation, and execute reproducible mini-workflows every\n",
    "  time code is shared or updated.\n",
    "  This ensures that the project stays healthy, reproducible, and\n",
    "  transparent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## What You Will Learn\n",
    "\n",
    "In this lab, we will build a **minimal CCD image calibration package**\n",
    "and then apply workflow automation to it at multiple levels:\n",
    "1. Package & Testing:\n",
    "   Write simple calibration functions in a Python package and test\n",
    "   them with `pytest`.\n",
    "2. `make`:\n",
    "   Automate local development tasks such as testing, linting, and\n",
    "   running a small pipeline.\n",
    "3. `Snakemake`:\n",
    "   Scale up the calibration pipeline to handle many images in parallel.\n",
    "4. CI/CD with GitHub Actions:\n",
    "   Automate testing and documentation generation whenever code is\n",
    "   pushed to GitHub.\n",
    "\n",
    "By the end of this lab, you will see how automation tools turn\n",
    "individual scripts into a reproducible scientific workflow that is\n",
    "easier to run, easier to share, and easier to trust."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Part 1: Set up a Python Package with Tests\n",
    "\n",
    "In real research, we rarely write a single script that does\n",
    "everything.\n",
    "Instead, we build up small, reusable functions, things like \"combine\n",
    "all bias frames\" or \"subtract dark current\".\n",
    "Over time, these functions naturally belong in a package: a collection\n",
    "of modules that can be imported, tested, and reused across multiple\n",
    "projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "For this lab, let's create a toy package called `ccdmini`.\n",
    "Its job is to provide the most basic CCD calibration primitives:\n",
    "* `median_stack`:\n",
    "  combine multiple images (e.g., biases, darks, flats) into a single\n",
    "  master calibration frame by taking the median pixel-by-pixel.\n",
    "* `make_master_bias`, `make_master_dark`, `make_master_flat`:\n",
    "  convenience functions that wrap around `median_stack` and perform\n",
    "  normalizations where needed.\n",
    "* `apply_calibration`: apply the standard CCD calibration formula:\n",
    "  \\begin{align}\n",
    "    \\text{Calibrated Image} =\n",
    "    \\frac{(\\text{Raw Image} - \\text{Master Bias} - \\text{Master Dark})}{\\text{Master Flat}}\n",
    "  \\end{align}\n",
    "\n",
    "This is the exact same operation astronomers run on real raw CCD frames.\n",
    "In our case, we will use tiny synthetic arrays to keep things simple\n",
    "and fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Why packaging?\n",
    "\n",
    "Even though this is just a mock example, packaging matters because:\n",
    "\n",
    "* Reusability:\n",
    "  you can use the same functions in multiple projects or scripts.\n",
    "* Testability:\n",
    "  you can isolate and test each function with `pytest`.\n",
    "* Shareability:\n",
    "  once it's a package, you could publish it to PyPI, or share it\n",
    "  within a collaboration with version control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "We will create a tiny mock package that implements median stacking and\n",
    "CCD calibration:\n",
    "* `median_stack`:\n",
    "  median-combine many 2D arrays (for master bias/dark/flat).\n",
    "* `make_master_*`:\n",
    "  convenience wrappers.\n",
    "* `apply_calibration`:\n",
    "  `(raw - bias - dark) / flat` (with safe division).\n",
    "\n",
    "We will also add `pytest` tests to lock in expected behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Below, we use bash cells to create files and directories.\n",
    "All paths are rooted at `$REPO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose where to create the repo (EDIT THIS if you want a different location)\n",
    "\n",
    "repo = \"ccdmini\"\n",
    "\n",
    "from os import environ, path\n",
    "environ['REPO'] = path.join(environ.get('HOME'), repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Create the git repo and a basic tree\n",
    "git init \"$REPO\"\n",
    "echo \"Repository root: $REPO\"\n",
    "\n",
    "# Create the minimal Python package structure\n",
    "mkdir -p \"$REPO/src/ccdmini\" \"$REPO/tests\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Create a \"pyproject.toml\" file as we did in ASTR 513 homework\n",
    "# The syntax you see here is called a \"heredoc\" in `bash`\n",
    "\n",
    "cat << EOF > \"$REPO/pyproject.toml\" \n",
    "[project]\n",
    "name = \"ccdmini\"\n",
    "version = \"0.0.0\"\n",
    "description = \"Minimal CCD calibration primitives for ASTR 501\"\n",
    "requires-python = \">=3.8\"\n",
    "dependencies = [\"numpy\", \"pytest\"]\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Create a \"__init__.py\" file.\n",
    "# It is a required part of a python package.\n",
    "\n",
    "cat << EOF > \"$REPO/src/ccdmini/__init__.py\"\n",
    "\"\"\"\n",
    "ccdmini: Minimal CCD calibration primitives for ASTR 501.\n",
    "\n",
    "This package intentionally stays tiny to keep the focus on\n",
    "workflow/automation, while still representing real calibration steps.\n",
    "\"\"\"\n",
    "\n",
    "from .calib import (\n",
    "    median_stack,\n",
    "    make_master_bias,\n",
    "    make_master_dark,\n",
    "    make_master_flat,\n",
    "    apply_calibration,\n",
    ")\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Implement the core calibration functions\n",
    "# * median_stack: median-combine a list of 2D arrays\n",
    "# * make_master_bias/dark/flat: wrappers (flat gets normalized)\n",
    "# * apply_calibration: (raw - bias - dark) / flat with safe division\n",
    "\n",
    "cat << EOF > \"$REPO/src/ccdmini/calib.py\"\n",
    "import numpy as np\n",
    "\n",
    "def median_stack(arrays):\n",
    "    \"\"\"Median-combine a list of 2D arrays (H, W) to (H, W).\"\"\"\n",
    "    return np.median(np.stack(arrays, axis=0), axis=0)\n",
    "\n",
    "def make_master_bias(biases):\n",
    "    \"\"\"Master bias via median combine.\"\"\"\n",
    "    return median_stack(biases)\n",
    "\n",
    "def make_master_dark(darks):\n",
    "    \"\"\"Master dark via median combine (assumes matching exposure).\"\"\"\n",
    "    return median_stack(darks)\n",
    "\n",
    "def make_master_flat(flats):\n",
    "    \"\"\"Master flat via median combine, then normalize to unit median.\"\"\"\n",
    "    mf  = median_stack(flats)\n",
    "    med = float(np.median(mf))\n",
    "    if med <= 0:\n",
    "        raise ValueError(\"Flat median must be positive to normalize.\")\n",
    "    return mf / med\n",
    "\n",
    "\n",
    "def apply_calibration(raw, mbias, mdark, mflat):\n",
    "    \"\"\"Apply CCD calibration: (raw - mbias - mdark) / mflat.\"\"\"\n",
    "    denom = np.where(mflat==0, 1.0, mflat)\n",
    "    return (raw - mbias - mdark) / denom\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Add pytest tests to lock in behavior and catch regressions\n",
    "cat << EOF > \"$REPO/tests/test_calib.py\"\n",
    "import numpy as np\n",
    "\n",
    "from ccdmini.calib import (\n",
    "    median_stack,\n",
    "    make_master_bias,\n",
    "    make_master_dark,\n",
    "    make_master_flat,\n",
    "    apply_calibration,\n",
    ")\n",
    "\n",
    "def test_median_stack_is_pixelwise_median():\n",
    "    a = np.ones((3,3))\n",
    "    b = np.ones((3,3)) * 3\n",
    "    out = median_stack([a, b])\n",
    "    assert np.allclose(out, 2.0) # median of {1,3} is 2 everywhere\n",
    "\n",
    "def test_master_bias_and_dark_are_medians():\n",
    "    mb = make_master_bias([np.full((2,2), 100), np.full((2,2), 102)])\n",
    "    md = make_master_dark([np.full((2,2), 10),  np.full((2,2), 12)])\n",
    "    assert np.allclose(mb, 101)\n",
    "    assert np.allclose(md, 11)\n",
    "\n",
    "def test_master_flat_normalization_to_unit_median():\n",
    "    mf = make_master_flat([np.full((2,2), 2.0), np.full((2,2), 4.0)])\n",
    "    assert np.allclose(mf, 1.0)\n",
    "    assert np.allclose(np.median(mf), 1.0)\n",
    "\n",
    "def test_apply_calibration_recovers_signal():\n",
    "    true_signal = np.ones((4,4)) * 1000.0\n",
    "    mb = np.ones((4,4)) * 100.0\n",
    "    md = np.ones((4,4)) * 10.0\n",
    "    mf = np.ones((4,4)) * 1.0\n",
    "    \n",
    "    raw = true_signal + mb + md  # construct a raw that should calibrate back to true_signal\n",
    "\n",
    "    cal = apply_calibration(raw, mb, md, mf)    \n",
    "    assert np.allclose(cal, true_signal)\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Track changes with git\n",
    "\n",
    "cd \"$REPO\"\n",
    "\n",
    "git add .\n",
    "git commit -m \"Initial commit --- 'ccdmini' for ASTR 501\"\n",
    "\n",
    "git log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Install and test your package\n",
    "\n",
    "Let's install `ccdmini` in \"editing\" mode.\n",
    "Then run `pytest` to make sure all the tests are working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd \"$REPO\"\n",
    "\n",
    "python -m pip install -U pip\n",
    "python -m pip install -e . >/dev/null\n",
    "\n",
    "pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Create Scripts\n",
    "\n",
    "In order to interact with a python package, you very often need to\n",
    "write python scripts.\n",
    "This is not necessarily the best way to develop pipeline.\n",
    "Let's create a few python scripts that wrap around `ccdmini` that can\n",
    "be run as standard Unix/Linux (shell) programs.\n",
    "Let's save them in the `$REPO/scripts/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Make sure the scripts/ and data/ dirs exist\n",
    "mkdir -p \"$REPO/scripts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Generate tiny synthetic data (NumPy .npy files)\n",
    "\n",
    "cat << EOF > \"$REPO/scripts/mkobs\"\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "from os import makedirs, path\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(13)\n",
    "makedirs(\"data/bias\", exist_ok=True)\n",
    "makedirs(\"data/dark\", exist_ok=True)\n",
    "makedirs(\"data/flat\", exist_ok=True)\n",
    "makedirs(\"data/raw\",  exist_ok=True)\n",
    "\n",
    "def save(dir, i, arr):\n",
    "    np.save(path.join(dir, f\"f{i:03d}.npy\"), arr)\n",
    "\n",
    "shape = (64, 64)\n",
    "\n",
    "# Bias/Dark/Flat\n",
    "for i in range(10): save(\"data/bias\", i, 100 +     rng.normal(0,1,shape))\n",
    "for i in range(10): save(\"data/dark\", i,  10 +     rng.normal(0,1,shape))\n",
    "for i in range(10): save(\"data/flat\", i,   1 + 0.1*rng.normal(0,1,shape))\n",
    "\n",
    "# Raw frames: a Gaussian \"star\" + bias + dark + noise\n",
    "YY, XX = np.indices(shape)\n",
    "signal = 1000 * np.exp(-((XX-32)**2 + (YY-32)**2)/(2*6**2))\n",
    "\n",
    "for i in range(100):\n",
    "    noise = rng.normal(0,5,shape)\n",
    "    save(\"data/raw\", i, signal + 100 + 10 + noise)\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Build reference\n",
    "\n",
    "cat << EOF > \"$REPO/scripts/mkref\"\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "from os import path, makedirs\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from ccdmini.calib import make_master_bias, make_master_dark, make_master_flat\n",
    "\n",
    "mkref = {\n",
    "    'bias': make_master_bias,\n",
    "    'dark': make_master_dark,\n",
    "    'flat': make_master_flat,    \n",
    "}\n",
    "\n",
    "def load_dir(d):\n",
    "    return [np.load(p) for p in sorted(glob(path.join(d, \"*.npy\")))]\n",
    "\n",
    "from sys import argv\n",
    "if len(argv) < 3:\n",
    "    print(f'usage: {argv[0]} [bias|dark|flat] DIR')\n",
    "    exit()\n",
    "\n",
    "kind = argv[1]\n",
    "data = argv[2]\n",
    "\n",
    "makedirs(\"results/ref\", exist_ok=True)\n",
    "np.save(f\"results/ref/{kind}.npy\", mkref[kind](load_dir(data)))\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Apply calibration to a small subset (fast demo)\n",
    "\n",
    "cat << EOF > \"$REPO/scripts/calmini\"\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "from os  import makedirs, path\n",
    "from sys import argv\n",
    "import numpy as np\n",
    "\n",
    "from ccdmini.calib import apply_calibration\n",
    "\n",
    "from sys import argv\n",
    "if len(argv) <= 1:\n",
    "    print(f'usage: {argv[0]} FILE1 FILE2 ... FILEN')\n",
    "    exit()\n",
    "files = argv[1:]\n",
    "\n",
    "rb = np.load(\"results/ref/bias.npy\")\n",
    "rd = np.load(\"results/ref/dark.npy\")\n",
    "rf = np.load(\"results/ref/flat.npy\")\n",
    "\n",
    "makedirs(\"results\", exist_ok=True)\n",
    "for f in files:\n",
    "    raw = np.load(f)\n",
    "    cal = apply_calibration(raw, rb, rd, rf)\n",
    "    np.save(path.join(\"results\", path.basename(f)), cal)\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Mean stack of calibrated frames as a QA image\n",
    "\n",
    "cat << EOF > \"$REPO/scripts/mkplt\"\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "from os import makedirs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sys import argv\n",
    "if len(argv) <= 1:\n",
    "    print(f'usage: {argv[0]} FILE1 FILE2 ... FILEN')\n",
    "    exit()\n",
    "files = argv[1:]\n",
    "\n",
    "stack = np.mean([np.load(p) for p in files], axis=0)\n",
    "\n",
    "plt.imshow(stack, origin=\"lower\")\n",
    "plt.colorbar()\n",
    "\n",
    "makedirs(\"plots\", exist_ok=True)\n",
    "plt.savefig(\"plots/mean.png\", dpi=150, bbox_inches=\"tight\")\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Make all scripts executable\n",
    "\n",
    "chmod a+x ${REPO}/scripts/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Optionally, let's also commit these scripts to git\n",
    "\n",
    "cd $REPO\n",
    "git add scripts\n",
    "git commit -m 'Add calibration scripts'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Test the \"pipeline\"\n",
    "\n",
    "We can now run all the python scripts one by one and calibrate an\n",
    "image of the mock star!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd $REPO\n",
    "./scripts/mkobs\n",
    "./scripts/mkref bias data/bias\n",
    "./scripts/mkref dark data/dark\n",
    "./scripts/mkref flat data/flat\n",
    "./scripts/calmini data/raw/f*.npy\n",
    "./scripts/mkplt   results/f*.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Uncomment the following to clean up\n",
    "\n",
    "#cd $REPO && rm -rf data/ results/ plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# HANDSON: how would you automate the above \"pipeline\"?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Make\n",
    "\n",
    "In the above hands-on, you probably programed a bash script, e.g.,\n",
    "```bash\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "./scripts/mkobs\n",
    "./scripts/refbias\n",
    "./scripts/refdark\n",
    "./scripts/refflat\n",
    "./scripts/calmini data/raw/f*.npy\n",
    "./scripts/mkplt   results/f*.npy\n",
    "```\n",
    "called `runall`.\n",
    "You run `./runall` in the top level `ccdmini` repo, and this bash\n",
    "script just run the python scripts in `scripts/` one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "It does automate your \"pipeline\", but if anything breaks, e.g., the\n",
    "observation fails, some file is corrupted and `numpy` cannot read it,\n",
    "etc, then the whole pipeline just falls apart.\n",
    "\n",
    "One simple solution in bash is to chain the different steps with `&&`.\n",
    "Bash will look at the return value of the program at each step, and\n",
    "\"short short circuit\" when any process fails.\n",
    "May may even `||` your chain with an echo statement to print an error\n",
    "message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# HANDSON: try to use `&&` and `||` to chain up multiple Unix/Linux\n",
    "#          programs and observe the short circuit behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "But we can do better than that!\n",
    "\n",
    "`make` is a classic tool for automation and workflow management.\n",
    "It was originally designed for compiling software, but the core idea\n",
    "applies to any workflow where some files depend on others.\n",
    "\n",
    "In make:\n",
    "* A target is something you want to build (by default a file).\n",
    "* Each target has a list of prerequisites (the inputs it depends on).\n",
    "* Each target has a recipe (the commands to run if the target is out\n",
    "  of date).\n",
    "\n",
    "When you run `make target`, the program:\n",
    "1. Checks if the target file exists and whether it is older than its\n",
    "   prerequisites.\n",
    "2. If the target is missing or stale, it runs the recipe to rebuild\n",
    "   it.\n",
    "3. This process cascades through the dependency graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "Why use `make`?\n",
    "* Rebuild only what changed:\n",
    "  If you touch one raw file, only the products depending on that file\n",
    "  are rebuilt.\n",
    "* Parallelism for free:\n",
    "  Independent targets can run at the same time with `make -j`.\n",
    "* Readable documentation:\n",
    "  The `Makefile` captures your workflow in a structured, repeatable\n",
    "  way.\n",
    "* Extremely lightweight:\n",
    "  No databases, no servers, just a single file that works everywhere.\n",
    "\n",
    "In practice, `make` lets us move beyond brittle bash scripts.\n",
    "Instead of rerunning all steps every time, we can express the logical\n",
    "dependencies in our workflow and let `make` decide what needs\n",
    "updating."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
