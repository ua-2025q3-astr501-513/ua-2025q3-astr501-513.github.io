{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Neural Network with JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "In this lab, we will:\n",
    "1. Downloads and loads MNIST into NumPy arrays (if it doesn't already\n",
    "   exist locally).\n",
    "2. Builds a simple Multi-Layer Perceptron in JAX.\n",
    "3. Trains the network on MNIST.\n",
    "4. Evaluates the performance on test data.\n",
    "5. Provides a custom inference function for your own handwriting\n",
    "   images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "This lab is based on a\n",
    "[JAX example](https://github.com/jax-ml/jax/blob/main/examples/mnist_classifier_fromscratch.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Please notice that MNIST is the \"hello world\" for machine learning,\n",
    "and there are many many examples available online, including some\n",
    "simplier ones that use libraries:\n",
    "[JAX with pre-built optimizers](https://github.com/jax-ml/jax/blob/main/examples/mnist_classifier.py),\n",
    "[FLAX](https://flax.readthedocs.io/en/latest/mnist_tutorial.html),\n",
    "[pytorch](https://github.com/pytorch/examples/tree/main/mnist), and\n",
    "[Keras](https://www.tensorflow.org/datasets/keras_example)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## MNIST Data Loader\n",
    "\n",
    "We start by downloading the MNIST data set and store it locally.\n",
    "Our data loader will parse, reshape, normalize them, and return them\n",
    "in NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "base_url = \"https://storage.googleapis.com/cvdf-datasets/mnist/\"\n",
    "\n",
    "# File names\n",
    "files = {\n",
    "    \"train_images\": \"train-images-idx3-ubyte.gz\",\n",
    "    \"train_labels\": \"train-labels-idx1-ubyte.gz\",\n",
    "    \"test_images\":  \"t10k-images-idx3-ubyte.gz\",\n",
    "    \"test_labels\":  \"t10k-labels-idx1-ubyte.gz\",\n",
    "}\n",
    "\n",
    "for key, file in files.items():\n",
    "    if not isfile(file):\n",
    "        url = base_url + file\n",
    "        print(f\"Downloading {url} to {file}...\")\n",
    "        urlretrieve(url, file)\n",
    "    else:\n",
    "        print(f\"{file} exists; skip download\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import struct\n",
    "import array\n",
    "from jax import numpy as np\n",
    "\n",
    "# Parsing functions\n",
    "\n",
    "def parse_labels(file):\n",
    "    with gzip.open(file, \"rb\") as fh:\n",
    "        _magic, num_data = struct.unpack(\">II\", fh.read(8))\n",
    "        # Read the label data as 1-byte unsigned integers\n",
    "        return np.array(array.array(\"B\", fh.read()), dtype=np.uint8)\n",
    "\n",
    "def parse_images(file):\n",
    "    with gzip.open(file, \"rb\") as fh:\n",
    "        _magic, num_data, rows, cols = struct.unpack(\">IIII\", fh.read(16))\n",
    "        # Read the image data as 1-byte unsigned integers\n",
    "        images = np.array(array.array(\"B\", fh.read()), dtype=np.uint8)\n",
    "        # Reshape to (num_data, 28, 28)\n",
    "        images = images.reshape(num_data, rows, cols)\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse raw data\n",
    "\n",
    "train_images_raw = parse_images(files[\"train_images\"])\n",
    "train_labels_raw = parse_labels(files[\"train_labels\"])\n",
    "\n",
    "test_images_raw  = parse_images(files[\"test_images\"])\n",
    "test_labels_raw  = parse_labels(files[\"test_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the images, i.e., flatten and normalize images to [0, 1]\n",
    "def standardize(images):\n",
    "    return images.reshape(-1, 28*28).astype(np.float32) / 255\n",
    "\n",
    "train_images = standardize(train_images_raw)\n",
    "test_images  = standardize(test_images_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "def one_hot(labels, num_classes=10):\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "train_labels = one_hot(train_labels_raw, 10).astype(np.float32)\n",
    "test_labels  = one_hot(test_labels_raw,  10).astype(np.float32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
